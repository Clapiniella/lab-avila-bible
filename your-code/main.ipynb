{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Avila Bible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore the [**Avila Bible dataset**](https://archive.ics.uci.edu/ml/datasets/Avila) which has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. You will use supervised learning algorithms to figure out what feature patterns each copyist are likely to have and use our model to predict those copyist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before your start:\n",
    "    - Read the README.md file,\n",
    "    - Comment as much as you can and use the APIla-bible in the README.md,\n",
    "    - Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine-learning](https://miro.medium.com/proxy/1*halC1X4ydv_3yHYxKqvrwg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avila data set has been extracted from 800 images of the the **Avila Bible**, a giant Latin copy of the whole Bible produced during the XII century between Italy and Spain. The palaeographic analysis of the  manuscript has  individuated the presence of 12 copyists. The pages written by each copyist are not equally numerous. \n",
    "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What am I expected to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, your prediction task consists in associating each pattern to one of the 8 monks we will be evaluating (labeled as:  Marcus, Clarius, Philippus, Coronavirucus, Mongucus, Paithonius, Ubuntius, Esequlius). For that aim, you should: \n",
    "- Train a minimum of 4 different models\n",
    "- Perform a minimum of 4 Feature Extraction and Engineering techniques\n",
    "- Must contain a summary of the machine learning tools and algorithms\n",
    "- and the results or the score obtained with each of them\n",
    "\n",
    "You won't get much more instructions from now on. Remember to comment your code as much as you can. Keep the requirements in mind and have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one last piece of advice, take a moment to explore the data, remember this dataset contains two files: **train** and **test**. You will find both files in `data` folder. The **test** files contains the data you will predict for, therefore it does not include the labels.\n",
    "Use the **train** dataset as you wish, but don't forget to split it into **train** and **test** again so you can evaluate your models. Just be sure to train it again with the whole data before predicting.\n",
    "We have also included a **sample submission** which is of the exact shape and format you must use when evaluating your predictions against the groundtruth through the `APIla-bible`. It won't work unless it is the exact same shape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/training_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1  0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2 -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3 -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4 -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "\n",
       "          7         8         9         10  \n",
       "0  0.316412  0.188810  0.134922     Marcus  \n",
       "1  1.045014  0.282354 -0.448209    Clarius  \n",
       "2 -0.024328  0.905984 -0.877830  Philippus  \n",
       "3 -1.747116 -1.183175 -0.807380  Philippus  \n",
       "4 -3.108388 -2.991700 -1.141030  Philippus  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('../data/test_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>1.357345</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.190314</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.445253</td>\n",
       "      <td>-0.715453</td>\n",
       "      <td>0.189796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202992</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.527256</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>0.771662</td>\n",
       "      <td>0.144676</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.745333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019049</td>\n",
       "      <td>0.211237</td>\n",
       "      <td>-0.155578</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>-0.310094</td>\n",
       "      <td>-0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451232</td>\n",
       "      <td>-0.267686</td>\n",
       "      <td>0.335206</td>\n",
       "      <td>-0.831336</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.988787</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.025485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.227680</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.413447</td>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.480988</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.313536</td>\n",
       "      <td>0.256389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.017834  0.132725  0.125378  1.357345  0.261718  0.190314  0.182426   \n",
       "1 -0.202992 -0.000745 -3.210528 -0.527256  0.082961  0.771662  0.144676   \n",
       "2  1.019049  0.211237 -0.155578 -0.311855  0.261718  0.107265  0.484429   \n",
       "3  0.451232 -0.267686  0.335206 -0.831336  0.261718  0.024215  0.220177   \n",
       "4 -0.227680  0.109171  0.413447  0.118917  0.172340  0.480988  0.522180   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.445253 -0.715453  0.189796  \n",
       "1  0.098572  0.251173  0.745333  \n",
       "2  0.339303 -0.310094 -0.049630  \n",
       "3  0.988787  0.032902  0.025485  \n",
       "4  0.091562  0.313536  0.256389  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ubuntius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Coronavirucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1\n",
       "0               \n",
       "0      Philippus\n",
       "1       Ubuntius\n",
       "2      Esequlius\n",
       "3  Coronavirucus\n",
       "4      Philippus"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keep calm and code on!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - train your models, make the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     float64\n",
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "6     float64\n",
       "7     float64\n",
       "8     float64\n",
       "9     float64\n",
       "10     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking types of data\n",
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.021280</td>\n",
       "      <td>0.030684</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>-0.022127</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.032540</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>-0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.004481</td>\n",
       "      <td>3.661030</td>\n",
       "      <td>1.072319</td>\n",
       "      <td>1.002045</td>\n",
       "      <td>0.963679</td>\n",
       "      <td>1.108192</td>\n",
       "      <td>1.245215</td>\n",
       "      <td>1.012995</td>\n",
       "      <td>1.085821</td>\n",
       "      <td>0.985799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.498799</td>\n",
       "      <td>-2.426761</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-5.440122</td>\n",
       "      <td>-4.922215</td>\n",
       "      <td>-7.450257</td>\n",
       "      <td>-11.935457</td>\n",
       "      <td>-4.164819</td>\n",
       "      <td>-5.486218</td>\n",
       "      <td>-6.719324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.128929</td>\n",
       "      <td>-0.259834</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>-0.542563</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>-0.598658</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.555747</td>\n",
       "      <td>-0.372457</td>\n",
       "      <td>-0.528135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.056229</td>\n",
       "      <td>-0.055704</td>\n",
       "      <td>0.214288</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.058835</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.101115</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.053548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.216699</td>\n",
       "      <td>0.203385</td>\n",
       "      <td>0.349432</td>\n",
       "      <td>0.601905</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.522513</td>\n",
       "      <td>0.446679</td>\n",
       "      <td>0.646377</td>\n",
       "      <td>0.500624</td>\n",
       "      <td>0.491862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.819916</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.987152</td>\n",
       "      <td>1.066121</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>13.173081</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>11.911338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  12017.000000  12017.000000  12017.000000  12017.000000  12017.000000   \n",
       "mean       0.021280      0.030684     -0.000379     -0.022127      0.006801   \n",
       "std        1.004481      3.661030      1.072319      1.002045      0.963679   \n",
       "min       -3.498799     -2.426761     -3.210528     -5.440122     -4.922215   \n",
       "25%       -0.128929     -0.259834      0.064919     -0.542563      0.172340   \n",
       "50%        0.056229     -0.055704      0.214288      0.080127      0.261718   \n",
       "75%        0.216699      0.203385      0.349432      0.601905      0.261718   \n",
       "max       11.819916    386.000000     50.000000      3.987152      1.066121   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  12017.000000  12017.000000  12017.000000  12017.000000  12017.000000  \n",
       "mean      -0.001279      0.032540     -0.006720     -0.011368     -0.026942  \n",
       "std        1.108192      1.245215      1.012995      1.085821      0.985799  \n",
       "min       -7.450257    -11.935457     -4.164819     -5.486218     -6.719324  \n",
       "25%       -0.598658     -0.006326     -0.555747     -0.372457     -0.528135  \n",
       "50%       -0.058835      0.220177      0.101115      0.064084     -0.053548  \n",
       "75%        0.522513      0.446679      0.646377      0.500624      0.491862  \n",
       "max       53.000000     83.000000     13.173081     44.000000     11.911338  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276225</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>-0.149000</td>\n",
       "      <td>0.506669</td>\n",
       "      <td>0.216542</td>\n",
       "      <td>0.359647</td>\n",
       "      <td>0.457467</td>\n",
       "      <td>0.402110</td>\n",
       "      <td>0.232397</td>\n",
       "      <td>0.206983</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187618</td>\n",
       "      <td>0.058792</td>\n",
       "      <td>0.051810</td>\n",
       "      <td>0.484561</td>\n",
       "      <td>0.176889</td>\n",
       "      <td>-0.235185</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.694277</td>\n",
       "      <td>0.180889</td>\n",
       "      <td>-0.285762</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.090256</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>0.107655</td>\n",
       "      <td>-0.085552</td>\n",
       "      <td>0.173952</td>\n",
       "      <td>-0.526971</td>\n",
       "      <td>0.178836</td>\n",
       "      <td>-0.011431</td>\n",
       "      <td>0.555573</td>\n",
       "      <td>-0.567606</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.115711</td>\n",
       "      <td>-0.062368</td>\n",
       "      <td>0.120132</td>\n",
       "      <td>-0.557791</td>\n",
       "      <td>-0.066590</td>\n",
       "      <td>-0.343021</td>\n",
       "      <td>-0.071236</td>\n",
       "      <td>-0.574300</td>\n",
       "      <td>-0.360741</td>\n",
       "      <td>-0.264636</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.101842</td>\n",
       "      <td>-0.030604</td>\n",
       "      <td>0.096399</td>\n",
       "      <td>-0.116400</td>\n",
       "      <td>0.058980</td>\n",
       "      <td>-0.195384</td>\n",
       "      <td>0.141750</td>\n",
       "      <td>-0.682696</td>\n",
       "      <td>-0.611992</td>\n",
       "      <td>-0.251983</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012</th>\n",
       "      <td>0.031903</td>\n",
       "      <td>-0.014324</td>\n",
       "      <td>-0.941505</td>\n",
       "      <td>-0.063462</td>\n",
       "      <td>0.117768</td>\n",
       "      <td>0.060289</td>\n",
       "      <td>0.107577</td>\n",
       "      <td>0.261194</td>\n",
       "      <td>0.094861</td>\n",
       "      <td>0.044953</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>-0.101221</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>-0.110834</td>\n",
       "      <td>0.113668</td>\n",
       "      <td>-0.666373</td>\n",
       "      <td>-0.117629</td>\n",
       "      <td>0.430473</td>\n",
       "      <td>-0.056519</td>\n",
       "      <td>-0.556008</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014</th>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>-0.909049</td>\n",
       "      <td>-0.170145</td>\n",
       "      <td>-0.229472</td>\n",
       "      <td>-0.061284</td>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.201129</td>\n",
       "      <td>0.195504</td>\n",
       "      <td>-0.060903</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12015</th>\n",
       "      <td>0.311288</td>\n",
       "      <td>0.191740</td>\n",
       "      <td>0.137092</td>\n",
       "      <td>-0.182721</td>\n",
       "      <td>0.337886</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>0.424819</td>\n",
       "      <td>0.548833</td>\n",
       "      <td>0.455570</td>\n",
       "      <td>-0.099455</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12016</th>\n",
       "      <td>0.787236</td>\n",
       "      <td>-0.018166</td>\n",
       "      <td>0.021393</td>\n",
       "      <td>-0.411275</td>\n",
       "      <td>0.160860</td>\n",
       "      <td>-0.110107</td>\n",
       "      <td>-0.034060</td>\n",
       "      <td>-0.369463</td>\n",
       "      <td>-0.172477</td>\n",
       "      <td>-0.070107</td>\n",
       "      <td>Coronavirucus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12017 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.276225  0.027025 -0.149000  0.506669  0.216542  0.359647  0.457467   \n",
       "1      0.187618  0.058792  0.051810  0.484561  0.176889 -0.235185  0.202128   \n",
       "2     -0.090256  0.045123  0.107655 -0.085552  0.173952 -0.526971  0.178836   \n",
       "3     -0.115711 -0.062368  0.120132 -0.557791 -0.066590 -0.343021 -0.071236   \n",
       "4     -0.101842 -0.030604  0.096399 -0.116400  0.058980 -0.195384  0.141750   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "12012  0.031903 -0.014324 -0.941505 -0.063462  0.117768  0.060289  0.107577   \n",
       "12013 -0.101221  0.008291  0.094574 -0.110834  0.113668 -0.666373 -0.117629   \n",
       "12014  0.003102  0.022139 -0.909049 -0.170145 -0.229472 -0.061284  0.073375   \n",
       "12015  0.311288  0.191740  0.137092 -0.182721  0.337886  0.029385  0.424819   \n",
       "12016  0.787236 -0.018166  0.021393 -0.411275  0.160860 -0.110107 -0.034060   \n",
       "\n",
       "              7         8         9             10  \n",
       "0      0.402110  0.232397  0.206983         Marcus  \n",
       "1      0.694277  0.180889 -0.285762        Clarius  \n",
       "2     -0.011431  0.555573 -0.567606      Philippus  \n",
       "3     -0.574300 -0.360741 -0.264636      Philippus  \n",
       "4     -0.682696 -0.611992 -0.251983      Philippus  \n",
       "...         ...       ...       ...            ...  \n",
       "12012  0.261194  0.094861  0.044953         Marcus  \n",
       "12013  0.430473 -0.056519 -0.556008      Philippus  \n",
       "12014  0.201129  0.195504 -0.060903         Marcus  \n",
       "12015  0.548833  0.455570 -0.099455         Marcus  \n",
       "12016 -0.369463 -0.172477 -0.070107  Coronavirucus  \n",
       "\n",
       "[12017 rows x 11 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipeline = [\n",
    "    StandardScaler(),\n",
    "    Normalizer(),\n",
    "]\n",
    "\n",
    "tr = make_pipeline(*pipeline)\n",
    "\n",
    "Xpr = tr.fit_transform(train_dataset[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']])\n",
    "train_dataset2 = pd.DataFrame(Xpr,columns=train_dataset[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']].columns)\n",
    "train_dataset2['10']=train_dataset['10']\n",
    "train_dataset2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.023337</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.084419</td>\n",
       "      <td>0.822759</td>\n",
       "      <td>0.152030</td>\n",
       "      <td>0.103838</td>\n",
       "      <td>0.087966</td>\n",
       "      <td>0.264775</td>\n",
       "      <td>-0.419162</td>\n",
       "      <td>0.116937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.065725</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>-0.932065</td>\n",
       "      <td>-0.148430</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>0.219138</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>0.029692</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.220845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770069</td>\n",
       "      <td>0.233697</td>\n",
       "      <td>-0.106320</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>0.198065</td>\n",
       "      <td>0.072042</td>\n",
       "      <td>0.348048</td>\n",
       "      <td>0.263461</td>\n",
       "      <td>-0.233972</td>\n",
       "      <td>-0.033027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.293214</td>\n",
       "      <td>-0.213890</td>\n",
       "      <td>0.240007</td>\n",
       "      <td>-0.554744</td>\n",
       "      <td>0.175076</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.127095</td>\n",
       "      <td>0.674436</td>\n",
       "      <td>0.026629</td>\n",
       "      <td>0.022213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.254864</td>\n",
       "      <td>0.175281</td>\n",
       "      <td>0.439458</td>\n",
       "      <td>0.146071</td>\n",
       "      <td>0.168438</td>\n",
       "      <td>0.472391</td>\n",
       "      <td>0.499691</td>\n",
       "      <td>0.096590</td>\n",
       "      <td>0.326133</td>\n",
       "      <td>0.270099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>-0.016978</td>\n",
       "      <td>0.641487</td>\n",
       "      <td>0.336688</td>\n",
       "      <td>-0.070542</td>\n",
       "      <td>0.296414</td>\n",
       "      <td>-0.460033</td>\n",
       "      <td>-0.221527</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.296598</td>\n",
       "      <td>-0.173128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>-0.033683</td>\n",
       "      <td>-0.297538</td>\n",
       "      <td>0.214735</td>\n",
       "      <td>0.132241</td>\n",
       "      <td>0.134879</td>\n",
       "      <td>0.630441</td>\n",
       "      <td>0.296631</td>\n",
       "      <td>-0.232799</td>\n",
       "      <td>0.265760</td>\n",
       "      <td>0.467200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8009</th>\n",
       "      <td>-0.041405</td>\n",
       "      <td>0.176046</td>\n",
       "      <td>0.156241</td>\n",
       "      <td>0.204140</td>\n",
       "      <td>0.165801</td>\n",
       "      <td>-0.601421</td>\n",
       "      <td>0.071507</td>\n",
       "      <td>0.493039</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>-0.513006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>0.070863</td>\n",
       "      <td>0.085367</td>\n",
       "      <td>0.206083</td>\n",
       "      <td>-0.439301</td>\n",
       "      <td>0.167189</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.146001</td>\n",
       "      <td>0.763623</td>\n",
       "      <td>0.309156</td>\n",
       "      <td>0.105970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>-0.002057</td>\n",
       "      <td>-0.070950</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.232138</td>\n",
       "      <td>0.144065</td>\n",
       "      <td>0.583158</td>\n",
       "      <td>0.162901</td>\n",
       "      <td>-0.422112</td>\n",
       "      <td>-0.047472</td>\n",
       "      <td>0.547870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8012 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.023337  0.119525  0.084419  0.822759  0.152030  0.103838  0.087966   \n",
       "1    -0.065725  0.008779 -0.932065 -0.148430  0.021328  0.219138  0.032388   \n",
       "2     0.770069  0.233697 -0.106320 -0.224216  0.198065  0.072042  0.348048   \n",
       "3     0.293214 -0.213890  0.240007 -0.554744  0.175076  0.007780  0.127095   \n",
       "4    -0.254864  0.175281  0.439458  0.146071  0.168438  0.472391  0.499691   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8007 -0.016978  0.641487  0.336688 -0.070542  0.296414 -0.460033 -0.221527   \n",
       "8008 -0.033683 -0.297538  0.214735  0.132241  0.134879  0.630441  0.296631   \n",
       "8009 -0.041405  0.176046  0.156241  0.204140  0.165801 -0.601421  0.071507   \n",
       "8010  0.070863  0.085367  0.206083 -0.439301  0.167189  0.114192  0.146001   \n",
       "8011 -0.002057 -0.070950  0.270400  0.232138  0.144065  0.583158  0.162901   \n",
       "\n",
       "             7         8         9  \n",
       "0     0.264775 -0.419162  0.116937  \n",
       "1     0.029692  0.075145  0.220845  \n",
       "2     0.263461 -0.233972 -0.033027  \n",
       "3     0.674436  0.026629  0.022213  \n",
       "4     0.096590  0.326133  0.270099  \n",
       "...        ...       ...       ...  \n",
       "8007  0.057971  0.296598 -0.173128  \n",
       "8008 -0.232799  0.265760  0.467200  \n",
       "8009  0.493039  0.025218 -0.513006  \n",
       "8010  0.763623  0.309156  0.105970  \n",
       "8011 -0.422112 -0.047472  0.547870  \n",
       "\n",
       "[8012 rows x 10 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpr = tr.fit_transform(test_dataset)\n",
    "test_dataset2 = pd.DataFrame(Xpr,columns=test_dataset.columns)\n",
    "test_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "5        0\n",
       "6        0\n",
       "7        0\n",
       "8        0\n",
       "9        0\n",
       "names    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking null values\n",
    "train_dataset2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Clarius',\n",
       " 'Coronavirucus',\n",
       " 'Esequlius',\n",
       " 'Marcus',\n",
       " 'Mongucus',\n",
       " 'Paithonius',\n",
       " 'Philippus',\n",
       " 'Ubuntius'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=set(train_dataset['10'])\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming classes in numbers\n",
    "LabelDiz={'Clarius':'1',\n",
    "          'Coronavirucus': '2',\n",
    "          'Esequlius':'3', \n",
    "          'Marcus':'4',\n",
    "          'Mongucus':'5',\n",
    "          'Paithonius': '6',\n",
    "          'Philippus':'7',\n",
    "          'Ubuntius':'8'\n",
    "         }\n",
    "def label(x):\n",
    "    return int(LabelDiz[x])\n",
    "train_dataset2['names']=train_dataset2['10'].apply(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        float64\n",
       "1        float64\n",
       "2        float64\n",
       "3        float64\n",
       "4        float64\n",
       "5        float64\n",
       "6        float64\n",
       "7        float64\n",
       "8        float64\n",
       "9        float64\n",
       "names      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the datatypes of the new column\n",
    "train_dataset2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAEWCAYAAADfK6SWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wF58S3UWuYfjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking correlation between variables\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "corr = train_dataset2.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(train_dataset2.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(train_dataset2.columns)\n",
    "ax.set_yticklabels(train_dataset2.columns)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are not very correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276225</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>-0.149000</td>\n",
       "      <td>0.506669</td>\n",
       "      <td>0.216542</td>\n",
       "      <td>0.359647</td>\n",
       "      <td>0.457467</td>\n",
       "      <td>0.402110</td>\n",
       "      <td>0.232397</td>\n",
       "      <td>0.206983</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187618</td>\n",
       "      <td>0.058792</td>\n",
       "      <td>0.051810</td>\n",
       "      <td>0.484561</td>\n",
       "      <td>0.176889</td>\n",
       "      <td>-0.235185</td>\n",
       "      <td>0.202128</td>\n",
       "      <td>0.694277</td>\n",
       "      <td>0.180889</td>\n",
       "      <td>-0.285762</td>\n",
       "      <td>Clarius</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.090256</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>0.107655</td>\n",
       "      <td>-0.085552</td>\n",
       "      <td>0.173952</td>\n",
       "      <td>-0.526971</td>\n",
       "      <td>0.178836</td>\n",
       "      <td>-0.011431</td>\n",
       "      <td>0.555573</td>\n",
       "      <td>-0.567606</td>\n",
       "      <td>Philippus</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.115711</td>\n",
       "      <td>-0.062368</td>\n",
       "      <td>0.120132</td>\n",
       "      <td>-0.557791</td>\n",
       "      <td>-0.066590</td>\n",
       "      <td>-0.343021</td>\n",
       "      <td>-0.071236</td>\n",
       "      <td>-0.574300</td>\n",
       "      <td>-0.360741</td>\n",
       "      <td>-0.264636</td>\n",
       "      <td>Philippus</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.101842</td>\n",
       "      <td>-0.030604</td>\n",
       "      <td>0.096399</td>\n",
       "      <td>-0.116400</td>\n",
       "      <td>0.058980</td>\n",
       "      <td>-0.195384</td>\n",
       "      <td>0.141750</td>\n",
       "      <td>-0.682696</td>\n",
       "      <td>-0.611992</td>\n",
       "      <td>-0.251983</td>\n",
       "      <td>Philippus</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.276225  0.027025 -0.149000  0.506669  0.216542  0.359647  0.457467   \n",
       "1  0.187618  0.058792  0.051810  0.484561  0.176889 -0.235185  0.202128   \n",
       "2 -0.090256  0.045123  0.107655 -0.085552  0.173952 -0.526971  0.178836   \n",
       "3 -0.115711 -0.062368  0.120132 -0.557791 -0.066590 -0.343021 -0.071236   \n",
       "4 -0.101842 -0.030604  0.096399 -0.116400  0.058980 -0.195384  0.141750   \n",
       "\n",
       "          7         8         9         10  names  \n",
       "0  0.402110  0.232397  0.206983     Marcus      4  \n",
       "1  0.694277  0.180889 -0.285762    Clarius      1  \n",
       "2 -0.011431  0.555573 -0.567606  Philippus      7  \n",
       "3 -0.574300 -0.360741 -0.264636  Philippus      7  \n",
       "4 -0.682696 -0.611992 -0.251983  Philippus      7  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset_X=train_dataset2[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']]\n",
    "train_dataset_y=train_dataset2['names']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataset_X, train_dataset_y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KMeans...\n",
      "Training SVC...\n",
      "Training LogisticRegression...\n",
      "Training KNeighbors...\n",
      "Training RandomFores...\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn import datasets, svm, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \n",
    "    \"KMeans\": KMeans( random_state=0),\n",
    "    \"SVC\": SVC(gamma='auto'),\n",
    "    \"LogisticRegression\": LogisticRegression(solver=\"lbfgs\" ),\n",
    "    \"KNeighbors\":KNeighborsClassifier(n_neighbors=3),\n",
    "    \"RandomFores\":RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "}\n",
    "\n",
    "# Train all the models in the models dict\n",
    "for name,m  in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    m.fit(X_train, y_train)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model KMeans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.25      0.18      0.21       485\n",
      "           2       0.04      0.06      0.05       203\n",
      "           3       0.05      0.25      0.08        81\n",
      "           4       0.53      0.24      0.33      1024\n",
      "           5       0.07      0.08      0.07       128\n",
      "           6       0.05      0.15      0.07       113\n",
      "           7       0.04      0.02      0.03       273\n",
      "           8       0.00      0.00      0.00        97\n",
      "\n",
      "    accuracy                           0.17      2404\n",
      "   macro avg       0.11      0.11      0.09      2404\n",
      "weighted avg       0.29      0.17      0.20      2404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silviaserafini/Library/Python/3.6/lib/python/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/silviaserafini/Library/Python/3.6/lib/python/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.26      0.33       485\n",
      "           2       0.95      0.83      0.88       203\n",
      "           3       0.00      0.00      0.00        81\n",
      "           4       0.58      0.92      0.71      1024\n",
      "           5       0.72      0.63      0.68       128\n",
      "           6       0.56      0.04      0.08       113\n",
      "           7       0.61      0.44      0.51       273\n",
      "           8       1.00      0.01      0.02        97\n",
      "\n",
      "    accuracy                           0.60      2404\n",
      "   macro avg       0.61      0.39      0.40      2404\n",
      "weighted avg       0.59      0.60      0.54      2404\n",
      "\n",
      "Evaluating model LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.29      0.35       485\n",
      "           2       0.91      0.86      0.88       203\n",
      "           3       0.33      0.01      0.02        81\n",
      "           4       0.59      0.85      0.69      1024\n",
      "           5       0.70      0.65      0.67       128\n",
      "           6       0.45      0.17      0.25       113\n",
      "           7       0.50      0.40      0.44       273\n",
      "           8       0.61      0.14      0.23        97\n",
      "\n",
      "    accuracy                           0.59      2404\n",
      "   macro avg       0.57      0.42      0.44      2404\n",
      "weighted avg       0.57      0.59      0.55      2404\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silviaserafini/Library/Python/3.6/lib/python/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model KNeighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.63      0.58       485\n",
      "           2       0.93      0.95      0.94       203\n",
      "           3       0.54      0.37      0.44        81\n",
      "           4       0.76      0.78      0.77      1024\n",
      "           5       0.81      0.80      0.81       128\n",
      "           6       0.54      0.47      0.50       113\n",
      "           7       0.71      0.60      0.65       273\n",
      "           8       0.57      0.40      0.47        97\n",
      "\n",
      "    accuracy                           0.70      2404\n",
      "   macro avg       0.67      0.63      0.65      2404\n",
      "weighted avg       0.70      0.70      0.70      2404\n",
      "\n",
      "Evaluating model RandomFores\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.75      0.81       485\n",
      "           2       1.00      0.95      0.97       203\n",
      "           3       0.97      0.74      0.84        81\n",
      "           4       0.85      0.96      0.90      1024\n",
      "           5       0.95      0.90      0.92       128\n",
      "           6       0.99      0.67      0.80       113\n",
      "           7       0.85      0.89      0.87       273\n",
      "           8       0.90      0.79      0.84        97\n",
      "\n",
      "    accuracy                           0.88      2404\n",
      "   macro avg       0.92      0.83      0.87      2404\n",
      "weighted avg       0.88      0.88      0.88      2404\n",
      "\n",
      "Train complete\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions={}\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions[name]=y_pred\n",
    "    print(f\"Evaluating model {name}\")\n",
    "    print(classification_report(y_test,y_pred))\n",
    "        \n",
    "\n",
    "print(\"Pred complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train themodel with the whole dataset\n",
    "RFmodel=RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "train_dataset_X=train_dataset[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']]\n",
    "train_dataset_y=train_dataset['10']\n",
    "m.fit(train_dataset_X, train_dataset_y)\n",
    "y_pred=model.predict(test_dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I do once I have a prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have already trained your model and made a prediction with it, you are ready to check what is the accuracy of it. \n",
    "\n",
    "Save your prediction as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(y_pred)\n",
    "df[0].value_counts()\n",
    "df.to_csv('res.csv',header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to know the truth! Are you good enough to call yourself a pro?\n",
    "\n",
    "Lucky you have the ultimate **APIla-bible** which give you the chance of checking the accuracy of your predictions as many times as you need in order to become the pro you want to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I post my prediction to the APIla-bible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy! You should only fulfil the path to your prediction `.csv` and run the cell below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9940089865202196,\n",
       " 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\",\n",
       " 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"res.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hope-you-enjoy](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
