{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Avila Bible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore the [**Avila Bible dataset**](https://archive.ics.uci.edu/ml/datasets/Avila) which has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. You will use supervised learning algorithms to figure out what feature patterns each copyist are likely to have and use our model to predict those copyist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before your start:\n",
    "    - Read the README.md file,\n",
    "    - Comment as much as you can and use the APIla-bible in the README.md,\n",
    "    - Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.svm import NuSVC, SVC, LinearSVC\n",
    "from sklearn.tree import ExtraTreeClassifier, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine-learning](https://miro.medium.com/proxy/1*halC1X4ydv_3yHYxKqvrwg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avila data set has been extracted from 800 images of the the **Avila Bible**, a giant Latin copy of the whole Bible produced during the XII century between Italy and Spain. The palaeographic analysis of the  manuscript has  individuated the presence of 12 copyists. The pages written by each copyist are not equally numerous. \n",
    "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What am I expected to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, your prediction task consists in associating each pattern to one of the 8 monks we will be evaluating (labeled as:  Marcus, Clarius, Philippus, Coronavirucus, Mongucus, Paithonius, Ubuntius, Esequlius). For that aim, you should: \n",
    "- Train a minimum of 4 different models\n",
    "- Perform a minimum of 4 Feature Extraction and Engineering techniques\n",
    "- Must contain a summary of the machine learning tools and algorithms\n",
    "- and the results or the score obtained with each of them\n",
    "\n",
    "You won't get much more instructions from now on. Remember to comment your code as much as you can. Keep the requirements in mind and have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one last piece of advice, take a moment to explore the data, remember this dataset contains two files: **train** and **test**. You will find both files in `data` folder. The **test** files contains the data you will predict for, therefore it does not include the labels.\n",
    "Use the **train** dataset as you wish, but don't forget to split it into **train** and **test** again so you can evaluate your models. Just be sure to train it again with the whole data before predicting.\n",
    "We have also included a **sample submission** which is of the exact shape and format you must use when evaluating your predictions against the groundtruth through the `APIla-bible`. It won't work unless it is the exact same shape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/training_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1  0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2 -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3 -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4 -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "\n",
       "          7         8         9         10  \n",
       "0  0.316412  0.188810  0.134922     Marcus  \n",
       "1  1.045014  0.282354 -0.448209    Clarius  \n",
       "2 -0.024328  0.905984 -0.877830  Philippus  \n",
       "3 -1.747116 -1.183175 -0.807380  Philippus  \n",
       "4 -3.108388 -2.991700 -1.141030  Philippus  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034603</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>-0.050536</td>\n",
       "      <td>0.406481</td>\n",
       "      <td>-0.051888</td>\n",
       "      <td>-0.034114</td>\n",
       "      <td>-0.064320</td>\n",
       "      <td>0.074687</td>\n",
       "      <td>-0.006808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.405835</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>-0.063053</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.575370</td>\n",
       "      <td>0.036323</td>\n",
       "      <td>0.318548</td>\n",
       "      <td>-0.026659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040097</td>\n",
       "      <td>0.405835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.108497</td>\n",
       "      <td>0.279027</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.162520</td>\n",
       "      <td>-0.064532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.050536</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>0.128052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084093</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.357121</td>\n",
       "      <td>0.274736</td>\n",
       "      <td>0.304903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406481</td>\n",
       "      <td>-0.063053</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.084093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>-0.078455</td>\n",
       "      <td>0.279677</td>\n",
       "      <td>0.145087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.051888</td>\n",
       "      <td>0.396154</td>\n",
       "      <td>0.108497</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469109</td>\n",
       "      <td>-0.035121</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>0.776504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.034114</td>\n",
       "      <td>0.575370</td>\n",
       "      <td>0.279027</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>0.469109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>0.264194</td>\n",
       "      <td>0.299467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.064320</td>\n",
       "      <td>0.036323</td>\n",
       "      <td>0.030528</td>\n",
       "      <td>0.357121</td>\n",
       "      <td>-0.078455</td>\n",
       "      <td>-0.035121</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500367</td>\n",
       "      <td>0.006262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.074687</td>\n",
       "      <td>0.318548</td>\n",
       "      <td>0.162520</td>\n",
       "      <td>0.274736</td>\n",
       "      <td>0.279677</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>0.264194</td>\n",
       "      <td>0.500367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.006808</td>\n",
       "      <td>-0.026659</td>\n",
       "      <td>-0.064532</td>\n",
       "      <td>0.304903</td>\n",
       "      <td>0.145087</td>\n",
       "      <td>0.776504</td>\n",
       "      <td>0.299467</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.200680</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000 -0.034603  0.040097 -0.050536  0.406481 -0.051888 -0.034114   \n",
       "1 -0.034603  1.000000  0.405835 -0.003220 -0.063053  0.396154  0.575370   \n",
       "2  0.040097  0.405835  1.000000  0.128052  0.000590  0.108497  0.279027   \n",
       "3 -0.050536 -0.003220  0.128052  1.000000  0.084093  0.254600  0.066038   \n",
       "4  0.406481 -0.063053  0.000590  0.084093  1.000000  0.042959  0.019530   \n",
       "5 -0.051888  0.396154  0.108497  0.254600  0.042959  1.000000  0.469109   \n",
       "6 -0.034114  0.575370  0.279027  0.066038  0.019530  0.469109  1.000000   \n",
       "7 -0.064320  0.036323  0.030528  0.357121 -0.078455 -0.035121  0.024779   \n",
       "8  0.074687  0.318548  0.162520  0.274736  0.279677  0.220883  0.264194   \n",
       "9 -0.006808 -0.026659 -0.064532  0.304903  0.145087  0.776504  0.299467   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.064320  0.074687 -0.006808  \n",
       "1  0.036323  0.318548 -0.026659  \n",
       "2  0.030528  0.162520 -0.064532  \n",
       "3  0.357121  0.274736  0.304903  \n",
       "4 -0.078455  0.279677  0.145087  \n",
       "5 -0.035121  0.220883  0.776504  \n",
       "6  0.024779  0.264194  0.299467  \n",
       "7  1.000000  0.500367  0.006262  \n",
       "8  0.500367  1.000000  0.200680  \n",
       "9  0.006262  0.200680  1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('../data/test_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>1.357345</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.190314</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.445253</td>\n",
       "      <td>-0.715453</td>\n",
       "      <td>0.189796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202992</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.527256</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>0.771662</td>\n",
       "      <td>0.144676</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.745333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019049</td>\n",
       "      <td>0.211237</td>\n",
       "      <td>-0.155578</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>-0.310094</td>\n",
       "      <td>-0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451232</td>\n",
       "      <td>-0.267686</td>\n",
       "      <td>0.335206</td>\n",
       "      <td>-0.831336</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.988787</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.025485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.227680</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.413447</td>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.480988</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.313536</td>\n",
       "      <td>0.256389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.017834  0.132725  0.125378  1.357345  0.261718  0.190314  0.182426   \n",
       "1 -0.202992 -0.000745 -3.210528 -0.527256  0.082961  0.771662  0.144676   \n",
       "2  1.019049  0.211237 -0.155578 -0.311855  0.261718  0.107265  0.484429   \n",
       "3  0.451232 -0.267686  0.335206 -0.831336  0.261718  0.024215  0.220177   \n",
       "4 -0.227680  0.109171  0.413447  0.118917  0.172340  0.480988  0.522180   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.445253 -0.715453  0.189796  \n",
       "1  0.098572  0.251173  0.745333  \n",
       "2  0.339303 -0.310094 -0.049630  \n",
       "3  0.988787  0.032902  0.025485  \n",
       "4  0.091562  0.313536  0.256389  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ubuntius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coronavirucus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1\n",
       "0               \n",
       "0      Philippus\n",
       "1       Ubuntius\n",
       "2      Esequlius\n",
       "3  Coronavirucus\n",
       "4      Philippus"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keep calm and code on!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - train your models, make the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "X = train_dataset.drop(columns=[\"10\"])\n",
    "y = train_dataset['10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9613, 10) (2404, 10) (9613,) (2404,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    #Multiclass as One-Vs-One: ambos del tipo SVM usados para clasificacion\n",
    "    \"NuSupport\": NuSVC(nu=0.1),\n",
    "    \"CSupport\": SVC(C=1.0),\n",
    "    #Multiclass as One-Vs-The-Rest\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(), # dentro de ensemble methods\n",
    "    \"Linear\": LinearSVC(multi_class=\"ovr\"), #del tipo SVM usados para clasificacion\n",
    "    \"Logistic\": LogisticRegression(multi_class=\"ovr\"), # dentro del modelo lineal\n",
    "    \"LogisCV\": LogisticRegressionCV(Cs=10, multi_class=\"ovr\"), #dentro del modelo lineal\n",
    "    #Support multilabel\n",
    "    \"DecTree\": DecisionTreeClassifier(), #decision tree-based models for classification (a non-parametric supervised learning )\n",
    "    \"ExtraTree\": ExtraTreeClassifier(), #decision tree-based models for classification (a non-parametric supervised learning )\n",
    "    \"KNeigh\": KNeighborsClassifier(n_neighbors=5), #classification for data with discrete labels\n",
    "    \"NN\": MLPClassifier(), #dentro de los modelos Neural network \n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100), # dentro de ensemble methods\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for NuSupport model is: 0.7371048252911814\n",
      "Score for CSupport model is: 0.668053244592346\n",
      "Score for GradientBoosting model is: 0.9276206322795341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flori/.local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Linear model is: 0.5162229617304492\n",
      "Score for Logistic model is: 0.5299500831946755\n",
      "Score for LogisCV model is: 0.512063227953411\n",
      "Score for DecTree model is: 0.968801996672213\n",
      "Score for ExtraTree model is: 0.8826955074875208\n",
      "Score for KNeigh model is: 0.7296173044925125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flori/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for NN model is: 0.7753743760399334\n",
      "Score for RandomForest model is: 0.9800332778702163\n"
     ]
    }
   ],
   "source": [
    "for name,m  in models.items():\n",
    "    m.fit(X_train, y_train)\n",
    "    #y_train_pred = m.predict(X_test)\n",
    "    #y_scores = m.predict_proba(X_test)  #Return probability estimates for the vector X\n",
    "    scores = m.score(X_test, y_test) #Return the mean accuracy on the given test data and labels.\n",
    "    print(f\"Score for {name} model is: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los modelos LinearSVC y MLPClassifier no han convergido ni llegando al máximo de iteraciones, los descartamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessClassifier(copy_X_train=True, kernel=None, max_iter_predict=100,\n",
       "                          multi_class='one_vs_one', n_jobs=None,\n",
       "                          n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
       "                          random_state=None, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lo he probado aparte porque tarda mucho en generar el modelo\n",
    "m = GaussianProcessClassifier(multi_class = \"one_vs_one\")\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333610648918469"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_pred = m.predict(X_test)\n",
    "scores = m.score(X_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos lineales no predicen bien (LogisticRegression,LogisticRegressionCV)\n",
    "Los 3 mejores modelos son :  RandomForestClassifier, DecisionTreeClassifier, GradientBoostingClassifier. Por tanto voy a reentrenar esto modelos con el data train completo (sin hacer split)\n",
    "\n",
    "Dos de los mejores modelos pertenecen a la clase de los modelos ensemble (RandomForestClassifier,GradientBoostingClassifier):\n",
    "\n",
    "1) RandomForestClassifier es un algoritmo Bagging: lo que implica que toman multiples muestras del train dataset (con reemplzamiento) y entrenan un modelo con cada muestra. La prediccion es una media de las predicciones de todas las muestras modeladas. Ademásreduce la correlacion entre los clasificadores.\n",
    "\n",
    "2) GradientBoostingClassifier pertenece a los algoritmos Boosting Algorithms: crea una secuencia de modelos que intenta corregir los errores de los modelos anteriores.\n",
    "\n",
    "En cuanto a DecisionTreeClassifier o modelos Decision Tree, el algoritmo aprende un set de preguntas si/si no que llevan a la decision. Pueden combinar tanto datos categoricos como numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reentreno los modelos esta vez con el datset completo\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X, y)\n",
    "y_predBoosting = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "y_predDecTree = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "y_predRandomForest = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I do once I have a prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have already trained your model and made a prediction with it, you are ready to check what is the accuracy of it. \n",
    "\n",
    "Save your prediction as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "test_Bossting = pd.DataFrame(y_predBoosting) \n",
    "test_DecisionTree = pd.DataFrame(y_predDecTree)\n",
    "test_RandomForest = pd.DataFrame(y_predRandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Bossting.to_csv(\"../data/test_Boosting.csv\", header = None)\n",
    "test_DecisionTree.to_csv(\"../data/test_DecTree.csv\", header = None)\n",
    "test_RandomForest.to_csv(\"../data/test_RandomForest.csv\", header = None)                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to know the truth! Are you good enough to call yourself a pro?\n",
    "\n",
    "Lucky you have the ultimate **APIla-bible** which give you the chance of checking the accuracy of your predictions as many times as you need in order to become the pro you want to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I post my prediction to the APIla-bible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy! You should only fulfil the path to your prediction `.csv` and run the cell below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9377184223664503,\n",
       " 'quote': \"Great job! That's an impressive score. Will you give it an extra push? Almost at the top, care for a final `boost`?\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/test_Boosting.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9883924113829257,\n",
       " 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\",\n",
       " 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/test_DecTree.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9936345481777334,\n",
       " 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\",\n",
       " 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/test_RandomForest.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hope-you-enjoy](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
