{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Avila Bible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will explore the [**Avila Bible dataset**](https://archive.ics.uci.edu/ml/datasets/Avila) which has been extracted from 800 images of the 'Avila Bible', an XII century giant Latin copy of the Bible. The prediction task consists in associating each pattern to a copyist. You will use supervised learning algorithms to figure out what feature patterns each copyist are likely to have and use our model to predict those copyist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before your start:\n",
    "    - Read the README.md file,\n",
    "    - Comment as much as you can and use the APIla-bible in the README.md,\n",
    "    - Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![machine-learning](https://miro.medium.com/proxy/1*halC1X4ydv_3yHYxKqvrwg.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avila data set has been extracted from 800 images of the the **Avila Bible**, a giant Latin copy of the whole Bible produced during the XII century between Italy and Spain. The palaeographic analysis of the  manuscript has  individuated the presence of 12 copyists. The pages written by each copyist are not equally numerous. \n",
    "Each pattern contains 10 features and corresponds to a group of 4 consecutive rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What am I expected to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, your prediction task consists in associating each pattern to one of the 8 monks we will be evaluating (labeled as:  Marcus, Clarius, Philippus, Coronavirucus, Mongucus, Paithonius, Ubuntius, Esequlius). For that aim, you should: \n",
    "- Train a minimum of 4 different models\n",
    "- Perform a minimum of 4 Feature Extraction and Engineering techniques\n",
    "- Must contain a summary of the machine learning tools and algorithms\n",
    "- and the results or the score obtained with each of them\n",
    "\n",
    "You won't get much more instructions from now on. Remember to comment your code as much as you can. Keep the requirements in mind and have fun! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one last piece of advice, take a moment to explore the data, remember this dataset contains two files: **train** and **test**. You will find both files in `data` folder. The **test** files contains the data you will predict for, therefore it does not include the labels.\n",
    "Use the **train** dataset as you wish, but don't forget to split it into **train** and **test** again so you can evaluate your models. Just be sure to train it again with the whole data before predicting.\n",
    "We have also included a **sample submission** which is of the exact shape and format you must use when evaluating your predictions against the groundtruth through the `APIla-bible`. It won't work unless it is the exact same shape. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/training_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.241386</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>-0.127126</td>\n",
       "      <td>0.380626</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.314889</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.316412</td>\n",
       "      <td>0.188810</td>\n",
       "      <td>0.134922</td>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303106</td>\n",
       "      <td>0.352558</td>\n",
       "      <td>0.082701</td>\n",
       "      <td>0.703981</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.391033</td>\n",
       "      <td>0.408929</td>\n",
       "      <td>1.045014</td>\n",
       "      <td>0.282354</td>\n",
       "      <td>-0.448209</td>\n",
       "      <td>Clarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116585</td>\n",
       "      <td>0.281897</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>-0.152490</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.889332</td>\n",
       "      <td>0.371178</td>\n",
       "      <td>-0.024328</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>-0.877830</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.326430</td>\n",
       "      <td>-0.652394</td>\n",
       "      <td>0.384996</td>\n",
       "      <td>-1.694222</td>\n",
       "      <td>-0.185173</td>\n",
       "      <td>-1.138481</td>\n",
       "      <td>-0.232828</td>\n",
       "      <td>-1.747116</td>\n",
       "      <td>-1.183175</td>\n",
       "      <td>-0.807380</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.437525</td>\n",
       "      <td>-0.471816</td>\n",
       "      <td>0.463236</td>\n",
       "      <td>-0.545248</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.972381</td>\n",
       "      <td>0.824183</td>\n",
       "      <td>-3.108388</td>\n",
       "      <td>-2.991700</td>\n",
       "      <td>-1.141030</td>\n",
       "      <td>Philippus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.241386  0.109171 -0.127126  0.380626  0.172340  0.314889  0.484429   \n",
       "1  0.303106  0.352558  0.082701  0.703981  0.261718 -0.391033  0.408929   \n",
       "2 -0.116585  0.281897  0.175168 -0.152490  0.261718 -0.889332  0.371178   \n",
       "3 -0.326430 -0.652394  0.384996 -1.694222 -0.185173 -1.138481 -0.232828   \n",
       "4 -0.437525 -0.471816  0.463236 -0.545248  0.261718 -0.972381  0.824183   \n",
       "\n",
       "          7         8         9         10  \n",
       "0  0.316412  0.188810  0.134922     Marcus  \n",
       "1  1.045014  0.282354 -0.448209    Clarius  \n",
       "2 -0.024328  0.905984 -0.877830  Philippus  \n",
       "3 -1.747116 -1.183175 -0.807380  Philippus  \n",
       "4 -3.108388 -2.991700 -1.141030  Philippus  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv('../data/test_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017834</td>\n",
       "      <td>0.132725</td>\n",
       "      <td>0.125378</td>\n",
       "      <td>1.357345</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.190314</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.445253</td>\n",
       "      <td>-0.715453</td>\n",
       "      <td>0.189796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202992</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-0.527256</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>0.771662</td>\n",
       "      <td>0.144676</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.251173</td>\n",
       "      <td>0.745333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.019049</td>\n",
       "      <td>0.211237</td>\n",
       "      <td>-0.155578</td>\n",
       "      <td>-0.311855</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.484429</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>-0.310094</td>\n",
       "      <td>-0.049630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.451232</td>\n",
       "      <td>-0.267686</td>\n",
       "      <td>0.335206</td>\n",
       "      <td>-0.831336</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.988787</td>\n",
       "      <td>0.032902</td>\n",
       "      <td>0.025485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.227680</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.413447</td>\n",
       "      <td>0.118917</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>0.480988</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.313536</td>\n",
       "      <td>0.256389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.017834  0.132725  0.125378  1.357345  0.261718  0.190314  0.182426   \n",
       "1 -0.202992 -0.000745 -3.210528 -0.527256  0.082961  0.771662  0.144676   \n",
       "2  1.019049  0.211237 -0.155578 -0.311855  0.261718  0.107265  0.484429   \n",
       "3  0.451232 -0.267686  0.335206 -0.831336  0.261718  0.024215  0.220177   \n",
       "4 -0.227680  0.109171  0.413447  0.118917  0.172340  0.480988  0.522180   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.445253 -0.715453  0.189796  \n",
       "1  0.098572  0.251173  0.745333  \n",
       "2  0.339303 -0.310094 -0.049630  \n",
       "3  0.988787  0.032902  0.025485  \n",
       "4  0.091562  0.313536  0.256389  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv', header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marcus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Esequlius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1\n",
       "0           \n",
       "0     Marcus\n",
       "1  Esequlius\n",
       "2     Marcus\n",
       "3     Marcus\n",
       "4  Esequlius"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keep calm and code on!`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - train your models, make the best prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     float64\n",
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "6     float64\n",
       "7     float64\n",
       "8     float64\n",
       "9     float64\n",
       "10     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marcus           5107\n",
       "Clarius          2362\n",
       "Philippus        1360\n",
       "Coronavirucus    1009\n",
       "Mongucus          640\n",
       "Paithonius        600\n",
       "Ubuntius          512\n",
       "Esequlius         427\n",
       "Name: 10, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"10\"].value_counts()#Nombres muy top!!:D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12017, 11)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "      <td>12017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.021280</td>\n",
       "      <td>0.030684</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>-0.022127</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.032540</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>-0.011368</td>\n",
       "      <td>-0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.004481</td>\n",
       "      <td>3.661030</td>\n",
       "      <td>1.072319</td>\n",
       "      <td>1.002045</td>\n",
       "      <td>0.963679</td>\n",
       "      <td>1.108192</td>\n",
       "      <td>1.245215</td>\n",
       "      <td>1.012995</td>\n",
       "      <td>1.085821</td>\n",
       "      <td>0.985799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.498799</td>\n",
       "      <td>-2.426761</td>\n",
       "      <td>-3.210528</td>\n",
       "      <td>-5.440122</td>\n",
       "      <td>-4.922215</td>\n",
       "      <td>-7.450257</td>\n",
       "      <td>-11.935457</td>\n",
       "      <td>-4.164819</td>\n",
       "      <td>-5.486218</td>\n",
       "      <td>-6.719324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.128929</td>\n",
       "      <td>-0.259834</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>-0.542563</td>\n",
       "      <td>0.172340</td>\n",
       "      <td>-0.598658</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>-0.555747</td>\n",
       "      <td>-0.372457</td>\n",
       "      <td>-0.528135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.056229</td>\n",
       "      <td>-0.055704</td>\n",
       "      <td>0.214288</td>\n",
       "      <td>0.080127</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>-0.058835</td>\n",
       "      <td>0.220177</td>\n",
       "      <td>0.101115</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.053548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.216699</td>\n",
       "      <td>0.203385</td>\n",
       "      <td>0.349432</td>\n",
       "      <td>0.601905</td>\n",
       "      <td>0.261718</td>\n",
       "      <td>0.522513</td>\n",
       "      <td>0.446679</td>\n",
       "      <td>0.646377</td>\n",
       "      <td>0.500624</td>\n",
       "      <td>0.491862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.819916</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.987152</td>\n",
       "      <td>1.066121</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>13.173081</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>11.911338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  12017.000000  12017.000000  12017.000000  12017.000000  12017.000000   \n",
       "mean       0.021280      0.030684     -0.000379     -0.022127      0.006801   \n",
       "std        1.004481      3.661030      1.072319      1.002045      0.963679   \n",
       "min       -3.498799     -2.426761     -3.210528     -5.440122     -4.922215   \n",
       "25%       -0.128929     -0.259834      0.064919     -0.542563      0.172340   \n",
       "50%        0.056229     -0.055704      0.214288      0.080127      0.261718   \n",
       "75%        0.216699      0.203385      0.349432      0.601905      0.261718   \n",
       "max       11.819916    386.000000     50.000000      3.987152      1.066121   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  12017.000000  12017.000000  12017.000000  12017.000000  12017.000000  \n",
       "mean      -0.001279      0.032540     -0.006720     -0.011368     -0.026942  \n",
       "std        1.108192      1.245215      1.012995      1.085821      0.985799  \n",
       "min       -7.450257    -11.935457     -4.164819     -5.486218     -6.719324  \n",
       "25%       -0.598658     -0.006326     -0.555747     -0.372457     -0.528135  \n",
       "50%       -0.058835      0.220177      0.101115      0.064084     -0.053548  \n",
       "75%        0.522513      0.446679      0.646377      0.500624      0.491862  \n",
       "max       53.000000     83.000000     13.173081     44.000000     11.911338  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feauture Vector\n",
    "X = train_dataset.drop(columns=[\"10\"])\n",
    "#GroundTruth\n",
    "y = train_dataset[\"10\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svm-rbf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/home/maria/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n",
      "/home/maria/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:228: ConvergenceWarning: Solver terminated early (max_iter=200).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training svc...\n",
      "Train complete\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"logis\": LogisticRegression(C=10,solver=\"lbfgs\"),\n",
    "    \"svm-rbf\": CalibratedClassifierCV(SVC(kernel=\"poly\",gamma=\"auto\", max_iter=200),cv=3),\n",
    "    \"svc\": SVC(),\n",
    "    \n",
    "}\n",
    "for name,m  in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    m.fit(X_train, y_train)\n",
    "print(\"Train complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model logis\n",
      "\t Accuracy: 0.565\n",
      "Evaluating model svm-rbf\n",
      "\t Accuracy: 0.533\n",
      "Evaluating model svc\n",
      "\t Accuracy: 0.687\n"
     ]
    }
   ],
   "source": [
    "printMetric = lambda label,value:print(f\"\\t {label}: {round(value,3)}\")\n",
    "y_predictDict=[]\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_predict = model.predict(test_dataset)\n",
    "    y_predictDict.append({\"model\":name,\"y_predict\":y_predict})\n",
    "    print(f\"Evaluating model {name}\")\n",
    "    printMetric(\"Accuracy\",accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGDClassifier...\n",
      "Training BaggingClassifier...\n",
      "Training MLPClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:554: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maria/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "models = {\n",
    "    \"SGDClassifier\":  SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5),\n",
    "    \"BaggingClassifier\": BaggingClassifier(KNeighborsClassifier()),\n",
    "    \"MLPClassifier\":  MLPClassifier(solver='lbfgs'),\n",
    "    \n",
    "   \n",
    "}\n",
    "for name,m  in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    m.fit(X_train, y_train)\n",
    "print(\"Train complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model SGDClassifier\n",
      "\t Accuracy: 0.493\n",
      "Evaluating model BaggingClassifier\n",
      "\t Accuracy: 0.757\n",
      "Evaluating model MLPClassifier\n",
      "\t Accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "printMetric = lambda label,value:print(f\"\\t {label}: {round(value,3)}\")\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_predict = model.predict(test_dataset)\n",
    "    y_predictDict.append({\"model\":name,\"y_predict\":y_predict})\n",
    "    print(f\"Evaluating model {name}\")\n",
    "    printMetric(\"Accuracy\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier...\n",
      "Training randomforest...\n",
      "Training GradientBoostingClassifier...\n",
      "Training HistGradientBoostingClassifier...\n",
      "Train complete\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"DecisionTreeClassifier\": tree.DecisionTreeClassifier(),\n",
    "    \"randomforest\": RandomForestClassifier(n_estimators=300),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(n_estimators=300), \n",
    "    \"HistGradientBoostingClassifier\": HistGradientBoostingClassifier()\n",
    "    }\n",
    "   \n",
    "for name,m  in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    m.fit(X_train, y_train)\n",
    "print(\"Train complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model DecisionTreeClassifier\n",
      "\t Accuracy: 0.984\n",
      "Evaluating model randomforest\n",
      "\t Accuracy: 0.993\n",
      "Evaluating model GradientBoostingClassifier\n",
      "\t Accuracy: 0.997\n",
      "Evaluating model HistGradientBoostingClassifier\n",
      "\t Accuracy: 0.998\n"
     ]
    }
   ],
   "source": [
    "printMetric = lambda label,value:print(f\"\\t {label}: {round(value,3)}\")\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_predict = model.predict(test_dataset)\n",
    "    y_predictDict.append({\"model\":name,\"y_predict\":y_predict})\n",
    "    print(f\"Evaluating model {name}\")\n",
    "    printMetric(\"Accuracy\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do I do once I have a prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have already trained your model and made a prediction with it, you are ready to check what is the accuracy of it. \n",
    "\n",
    "Save your prediction as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model:  logis\n",
      "{'accuracy': 0.5757613579630554, 'quote': 'Nope, not good enough. But you shall rise as the glorious phoenix from the ashes of this score and get to the top!'} \n",
      "\n",
      "For model:  svm-rbf\n",
      "{'accuracy': 0.5376934598102846, 'quote': 'Nope, not good enough. But you shall rise as the glorious phoenix from the ashes of this score and get to the top!'} \n",
      "\n",
      "For model:  svc\n",
      "{'accuracy': 0.6829755366949576, 'quote': 'Nope, not good enough. But you shall rise as the glorious phoenix from the ashes of this score and get to the top!'} \n",
      "\n",
      "For model:  SGDClassifier\n",
      "{'accuracy': 0.5008736894658014, 'quote': 'Nope, not good enough. But you shall rise as the glorious phoenix from the ashes of this score and get to the top!'} \n",
      "\n",
      "For model:  BaggingClassifier\n",
      "{'accuracy': 0.744882675986021, 'quote': \"Close, but no cigar. It's a good begining. How can you improve it more? Maybe try some different models?\"} \n",
      "\n",
      "For model:  MLPClassifier\n",
      "{'accuracy': 0.8170244633050424, 'quote': \"It's good, but I'm sure you can do better! Try different models, adjust the hyperparameters, some fine tuning can lead you a long way.\"} \n",
      "\n",
      "For model:  DecisionTreeClassifier\n",
      "{'accuracy': 0.9822765851223165, 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\", 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'} \n",
      "\n",
      "For model:  randomforest\n",
      "{'accuracy': 0.9898901647528707, 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\", 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'} \n",
      "\n",
      "For model:  GradientBoostingClassifier\n",
      "{'accuracy': 0.9988766849725412, 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\", 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'} \n",
      "\n",
      "For model:  HistGradientBoostingClassifier\n",
      "{'accuracy': 0.9995007488766849, 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\", 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "for e in y_predictDict:\n",
    "    y_predict=e[\"y_predict\"]\n",
    "    submission=pd.DataFrame(y_predict)\n",
    "    submission.to_csv(\"../data/sample_submission.csv\",header=None)\n",
    "    my_submission = \"../data/sample_submission.csv\"\n",
    "    with open(my_submission) as f:\n",
    "        res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "    print(\"For model: \",e[\"model\"])\n",
    "    print(res.json(),\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me salen 4 modelos con accuracy muy alto y por el tipo de datos, no se sobreajustó, habría que escoger modelos más generalista en otros casos en la realidad.\n",
    "\n",
    "For model DecisionTreeClassifier:\n",
    "{'accuracy': 0.9822765851223165}\n",
    "\n",
    "For model:  randomforest:\n",
    "{'accuracy': 0.9898901647528707}\n",
    "\n",
    "For model:  GradientBoostingClassifier\n",
    "{'accuracy': 0.9988766849725412}\n",
    "\n",
    "For model:  HistGradientBoostingClassifier\n",
    "{'accuracy': 0.9995007488766849}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to know the truth! Are you good enough to call yourself a pro?\n",
    "\n",
    "Lucky you have the ultimate **APIla-bible** which give you the chance of checking the accuracy of your predictions as many times as you need in order to become the pro you want to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I post my prediction to the APIla-bible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy peasy! You should only fulfil the path to your prediction `.csv` and run the cell below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9995007488766849,\n",
       " 'quote': \"AWESOME! A-W-E-S-O-M-E! Amazing score!!! So cool! I can't even... But wait, maybe...too good to be true? Overfit much?\",\n",
       " 'tip': 'If you think you may have overfitted your model, visit http://apila-bible.herokuapp.com/check/overfit on your browser for some follow up. ;)'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = \"../data/sample_submission.csv\"\n",
    "with open(my_submission) as f:\n",
    "    res = requests.post(\"http://apila-bible.herokuapp.com/check\", files={\"csv_data\":f.read()})\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hope-you-enjoy](https://imgs.xkcd.com/comics/machine_learning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
